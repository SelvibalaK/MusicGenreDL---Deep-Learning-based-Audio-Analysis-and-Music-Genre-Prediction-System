# MusicGenreDL
Welcome to the MusicGenreDL repository!

## About

This repository contains a deep learning project focused on analyzing audio data to predict music genres. The system leverages convolutional neural networks (CNNs) and advanced audio feature extraction techniques,
transforming raw audio files into visual representations like Mel Spectrograms to enable accurate genre classification. The dataset used includes audio files, visual spectrogram representations, and extracted
feature sets, providing a comprehensive foundation for model training and evaluation. Developed as part of an advanced machine learning initiative, this project offers a scalable solution for music genre prediction,
aiming for high performance and accuracy.

## Project Highlights

- **Music Genre Prediction:** Utilizes a CNN model trained on diverse audio data to classify tracks into ten different music genres, enhancing the accuracy and performance of the system.
- **Audio Feature Extraction:** Converts audio files into Mel Spectrograms and extracts key features like MFCCs, chroma, and spectral contrast, facilitating deep learning model input.
- **Comprehensive Dataset:** Incorporates three types of data—original audio files, visual spectrogram representations, and extracted audio features—ensuring a robust and versatile dataset for training.
- **Advanced CNN Architecture:** Implements a sophisticated CNN architecture that includes multiple layers of convolution, pooling, and dropout, optimized for high accuracy in genre classification.
- **InceptionV3 Architecture:** Integrates the InceptionV3 model, known for its efficiency in handling complex image data and feature extraction, to improve the accuracy of genre classification from Mel Spectrograms.
- **Data Augmentation:** Enhances the dataset with techniques like splitting audio files into shorter clips, increasing the volume of training data and improving model generalization.
- **Scalability:** Designed with scalability in mind, allowing for easy integration, adaptation to different audio datasets, and further enhancements to the model.
- **Visualization Tools:** Includes tools for visualizing audio features and spectrograms, aiding in model interpretability and understanding of audio data.
- **Model Training and Evaluation:** Provides scripts and notebooks for efficient model training, evaluation, and hyperparameter tuning, ensuring the model's robustness and performance.
- **Tool Used:** The entire project, including data preprocessing, model training, and evaluation, is conducted using TensorFlow and Keras within Jupyter notebooks, with Python as the primary programming language.

